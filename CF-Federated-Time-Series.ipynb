{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41567fa9-9d1e-428a-a33f-6fb7105bf9b3",
   "metadata": {},
   "source": [
    "<h1>Benchmarking Catastrophic Forgetting Mitigation Methods in Federated Time Series Forecasting </h1> \n",
    "\n",
    "Dataset link: https://archive.ics.uci.edu/dataset/501/beijing+multi+site+air+quality+data\n",
    "\n",
    "How to run:\n",
    "\n",
    "pip install -r requirements.txt\n",
    "\n",
    "Run each of the steps in order: \n",
    "\n",
    "1. Imports & Global Config (modify the hyperparameters)\n",
    "\n",
    "2. Data Loading, Basic Cleaning, Feature Engineering\n",
    "\n",
    "3. Splits, Global Robust Normalization, Lagged Samples\n",
    "\n",
    "4. Dataset & DataLoaders\n",
    "\n",
    "5. Model & Utilities (Base training or loading)\n",
    "\n",
    "6. Base Model: Train (optional) or Load (default for speed)\n",
    "\n",
    "7. Initialize Replay Buffers & Fisher (once)\n",
    "\n",
    "8. Continual learning function\n",
    "\n",
    "9. Run Ablation & Evaluate all the proposed methods (Naive, Replay, KD, EWC, O-EWC, SI)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c56be-fb88-4613-9f88-19b26b9b4974",
   "metadata": {},
   "source": [
    "<h2> 1. Imports & Global Config </h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9411af38-1c78-41be-8596-6533bea4b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\"figure.figsize\": (12, 6), \"axes.grid\": True})\n",
    "\n",
    "# ---- Device & deterministic seeds ----\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def set_all_seeds(seed: int = 42) -> None:\n",
    "    import random\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_all_seeds(42)\n",
    "\n",
    "# ---- Paths ----\n",
    "DATASET_DIR = Path(\"../dataset/AirQuality\")\n",
    "\n",
    "DATASET_FILES = [\n",
    "    \"Aotizhongxin.csv\",\"Changping.csv\",\"Dingling.csv\",\"Dongsi.csv\",\"Guanyuan.csv\",\"Gucheng.csv\",\n",
    "    \"Huairou.csv\",\"Nongzhanguan.csv\",\"Shunyi.csv\",\"Tiantan.csv\",\"Wanliu.csv\",\"Wanshouxigong.csv\"\n",
    "]\n",
    "\n",
    "# ---- Tasking & lags ----\n",
    "TARGET_COL = \"WSPM\"   # Change Target to forecast: PM2.5  or  TEMP\n",
    "N_LAGS   = 12\n",
    "PRED_LEN = 6\n",
    "SPLIT_RATIO = 0.8      # train/test split inside each task\n",
    "BATCH_SIZE  = 32\n",
    "\n",
    "# ----OFFLINE BASE FL MODEL ----\n",
    "NUM_ROUNDS_BASE = 200   # e.g., 500 longer FL pretraining\n",
    "LR_BASE = 1e-5\n",
    "LOCAL_EPOCHS_BASE = 1\n",
    "\n",
    "# ---- Continual learning knobs (can be light for a quick run) ----\n",
    "NUM_ROUNDS_CL = 25\n",
    "LOCAL_EPOCHS = 1\n",
    "LR = 1e-5\n",
    "\n",
    "# Coefficients (provide your paperâ€™s defaults)\n",
    "SI_COEFF          = 14\n",
    "KD_COEFF          = 120\n",
    "EWC_COEFF         = 1e8\n",
    "ONLINE_EWC_COEFF  = 1.3e6\n",
    "REPLAY_COEFF      = 0.8\n",
    "REPLAY_RATIO      = 0.15\n",
    "BUFFER_CAPACITY   = 100000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711e96d-3d9d-4022-9929-1678d15d4f54",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<h1>2. Data Loading, Basic Cleaning, Feature Engineering</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f3583d-c176-4839-b920-1170985fc791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load raw CSVs â†’ dict of clients\n",
    "def load_clients(dataset_dir: Path, files: List[str]) -> Dict[str, pd.DataFrame]:\n",
    "    clients = {}\n",
    "    for f in files:\n",
    "        df = pd.read_csv(dataset_dir / f)\n",
    "        df[\"time\"] = pd.to_datetime(df[[\"year\",\"month\",\"day\",\"hour\"]])\n",
    "        df = df.set_index(\"time\").sort_index()\n",
    "        clients[f.replace(\".csv\",\"\")] = df\n",
    "    return clients\n",
    "\n",
    "client_dfs = load_clients(DATASET_DIR, DATASET_FILES)\n",
    "\n",
    "# Missing-value handling\n",
    "def smart_imputation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    cont_cols = out.select_dtypes(include=[np.number]).columns\n",
    "    out[cont_cols] = out[cont_cols].interpolate(method=\"time\", limit_direction=\"both\")\n",
    "    if \"wd\" in out.columns:\n",
    "        out[\"wd\"] = out[\"wd\"].ffill().bfill()\n",
    "    out = out.dropna()\n",
    "    return out\n",
    "\n",
    "client_dfs = {k: smart_imputation(v) for k, v in client_dfs.items()}\n",
    "\n",
    "# Wind direction encoding\n",
    "WD2ANG = {'N':0,'NNE':22.5,'NE':45,'ENE':67.5,'E':90,'ESE':112.5,'SE':135,'SSE':157.5,\n",
    "          'S':180,'SSW':202.5,'SW':225,'WSW':247.5,'W':270,'WNW':292.5,'NW':315,'NNW':337.5}\n",
    "\n",
    "def encode_wind_direction(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    if \"wd\" in out.columns:\n",
    "        ang = out[\"wd\"].map(WD2ANG).fillna(0.0)\n",
    "        rad = np.deg2rad(ang)\n",
    "        out[\"wd_sin\"] = np.sin(rad); out[\"wd_cos\"] = np.cos(rad)\n",
    "    return out\n",
    "\n",
    "client_dfs = {k: encode_wind_direction(v) for k, v in client_dfs.items()}\n",
    "\n",
    "# Cyclical time features\n",
    "def add_time_cycles(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    if all(c in out.columns for c in [\"hour\",\"month\",\"day\"]):\n",
    "        out[\"hour_sin\"]  = np.sin(2*np.pi*out[\"hour\"]/24)\n",
    "        out[\"hour_cos\"]  = np.cos(2*np.pi*out[\"hour\"]/24)\n",
    "        out[\"month_sin\"] = np.sin(2*np.pi*out[\"month\"]/12)\n",
    "        out[\"month_cos\"] = np.cos(2*np.pi*out[\"month\"]/12)\n",
    "        out[\"day_sin\"]   = np.sin(2*np.pi*out[\"day\"]/31)\n",
    "        out[\"day_cos\"]   = np.cos(2*np.pi*out[\"day\"]/31)\n",
    "    return out\n",
    "\n",
    "client_dfs = {k: add_time_cycles(v) for k, v in client_dfs.items()}\n",
    "\n",
    "# Final feature set (include 'year' for global robust normalization bins)\n",
    "FEATURES = [\n",
    "    \"year\",\n",
    "    \"PM2.5\",\"PM10\",\"SO2\",\"NO2\",\"CO\",\"O3\",\n",
    "    \"TEMP\",\"PRES\",\"DEWP\",\"RAIN\",\"WSPM\",\n",
    "    \"wd_sin\",\"wd_cos\",\n",
    "    \"hour_sin\",\"hour_cos\",\"month_sin\",\"month_cos\",\"day_sin\",\"day_cos\",\n",
    "]\n",
    "client_dfs = {k: v[[c for c in FEATURES if c in v.columns]].copy() for k, v in client_dfs.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5dc876-7ab8-4481-b6a1-90593e2d9571",
   "metadata": {},
   "source": [
    " <h1>3. Splits, Global Robust Normalization, Lagged Samples</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e27cafac-465e-4cb5-ba97-f90874bea4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom chronological splits (base/train, base/test, tasks)\n",
    "TASK_RANGES = [\n",
    "    (\"2014-05-05\",\"2014-08-06\"),(\"2014-08-07\",\"2014-11-06\"),(\"2014-11-07\",\"2015-02-02\"),\n",
    "    (\"2015-02-03\",\"2015-05-04\"),(\"2015-05-05\",\"2015-08-06\"),(\"2015-08-07\",\"2015-11-06\"),\n",
    "    (\"2015-11-07\",\"2016-02-02\"),(\"2016-02-03\",\"2016-05-04\"),(\"2016-05-05\",\"2016-08-06\"),\n",
    "    (\"2016-08-07\",\"2016-11-06\"),(\"2016-11-07\",\"2017-02-02\"),\n",
    "]\n",
    "\n",
    "def split_ranges(df: pd.DataFrame) -> Tuple[pd.DataFrame,pd.DataFrame,List[pd.DataFrame]]:\n",
    "    base = df.loc[\"2013-05-01\":\"2014-05-03 23:00:00\"]\n",
    "    base_test = df.loc[\"2014-05-04\":\"2014-05-04 23:00:00\"]\n",
    "    tasks = [df.loc[s:e].copy() for (s,e) in TASK_RANGES if not df.loc[s:e].empty]\n",
    "    return base, base_test, tasks\n",
    "\n",
    "# Global robust [1,99] percentile bounds across all clients\n",
    "def compute_global_bounds(clients: Dict[str, pd.DataFrame], cols: List[str]) -> Dict[str, Tuple[float,float]]:\n",
    "    percs = {c: [] for c in cols}\n",
    "    for _, df in clients.items():\n",
    "        for c in cols:\n",
    "            if c in df and pd.api.types.is_numeric_dtype(df[c]):\n",
    "                arr = df[c].dropna().values\n",
    "                if arr.size:\n",
    "                    percs[c].append((np.percentile(arr,1), np.percentile(arr,99)))\n",
    "    bounds = {c: (min(x for x,_ in percs[c]), max(y for _,y in percs[c])) for c in cols if percs[c]}\n",
    "    return bounds\n",
    "\n",
    "GLOBAL_BOUNDS = compute_global_bounds(client_dfs, FEATURES)\n",
    "\n",
    "def normalize_df_globally(df: pd.DataFrame, bounds: Dict[str,Tuple[float,float]], ordered_cols: List[str]) -> pd.DataFrame:\n",
    "    out = df[ordered_cols].copy()\n",
    "    for c in out.columns:\n",
    "        if c in bounds and pd.api.types.is_numeric_dtype(out[c]):\n",
    "            lo, hi = bounds[c]\n",
    "            out[c] = 0.0 if hi == lo else (out[c]-lo)/(hi-lo)\n",
    "            out[c] = out[c].clip(0,1)\n",
    "    return out\n",
    "\n",
    "def create_lagged_samples(df: pd.DataFrame, n_lags: int, pred_len: int, target_col: str = \"WSPM\",\n",
    "                          include_target_in_input: bool = True) -> Tuple[np.ndarray,np.ndarray]:\n",
    "    cols = df.columns.tolist() if include_target_in_input else [c for c in df.columns if c != target_col]\n",
    "    Xv = df[cols].astype(np.float64).values\n",
    "    Yv = df[[target_col]].astype(np.float64).values\n",
    "    X, Y = [], []\n",
    "    for i in range(n_lags, len(df)-pred_len+1):\n",
    "        xw = Xv[i-n_lags:i]\n",
    "        yw = Yv[i:i+pred_len].flatten()\n",
    "        if np.isnan(xw).any() or np.isnan(yw).any(): \n",
    "            continue\n",
    "        X.append(xw); Y.append(yw)\n",
    "    return np.asarray(X), np.asarray(Y)\n",
    "\n",
    "# Build all lagged splits per client\n",
    "base_lagged, task_lagged = {}, {\"base_test\": {}}\n",
    "\n",
    "for client, df in client_dfs.items():\n",
    "    base, base_test, tasks = split_ranges(df)\n",
    "    base_n   = normalize_df_globally(base, GLOBAL_BOUNDS, FEATURES)\n",
    "    baseT_n  = normalize_df_globally(base_test, GLOBAL_BOUNDS, FEATURES)\n",
    "    Xb, yb   = create_lagged_samples(base_n, N_LAGS, PRED_LEN, TARGET_COL)\n",
    "    Xbt, ybt = create_lagged_samples(baseT_n, N_LAGS, PRED_LEN, TARGET_COL)\n",
    "\n",
    "    base_lagged[client] = {\"X\": Xb, \"y\": yb}\n",
    "    task_lagged[\"base_test\"][client] = {\"X\": Xbt, \"y\": ybt}\n",
    "\n",
    "    for t_idx, tdf in enumerate(tasks, 1):\n",
    "        tn = normalize_df_globally(tdf, GLOBAL_BOUNDS, FEATURES)\n",
    "        Xt, yt = create_lagged_samples(tn, N_LAGS, PRED_LEN, TARGET_COL)\n",
    "        task_lagged.setdefault(f\"task_{t_idx}\", {})[client] = {\"X\": Xt, \"y\": yt}\n",
    "\n",
    "\n",
    "NUM_TASKS = len([k for k in task_lagged if k.startswith(\"task_\")])\n",
    "assert NUM_TASKS > 0, \"No tasks found; check TASK_RANGES.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98894c24-48a0-427e-a8ef-cdfd4144f361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8b5088e-b2af-462f-b87a-481b61a0534b",
   "metadata": {},
   "source": [
    " <h1>4. Dataset & DataLoaders</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "761d5bac-942e-40d7-a341-c9e26127509b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_1: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_2: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_3: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_4: total = 2167\n",
      "ğŸ“ Wanshouxigong - task_5: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_6: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_7: total = 2095\n",
      "ğŸ“ Wanshouxigong - task_8: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_9: total = 2239\n",
      "ğŸ“ Wanshouxigong - task_10: total = 2191\n",
      "ğŸ“ Wanshouxigong - task_11: total = 2095\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = torch.as_tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.as_tensor(y, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\n",
    "client_dls = {\"base_train\": {}, \"base_test\": {}}\n",
    "for i in range(NUM_TASKS):\n",
    "    client_dls[f\"task_{i+1}_train\"] = {}\n",
    "    client_dls[f\"task_{i+1}_test\"]  = {}\n",
    "\n",
    "for c in base_lagged:\n",
    "    Xb, yb = base_lagged[c][\"X\"], base_lagged[c][\"y\"]\n",
    "    client_dls[\"base_train\"][c] = DataLoader(TimeSeriesDataset(Xb,yb), batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    Xbt, ybt = task_lagged[\"base_test\"][c][\"X\"], task_lagged[\"base_test\"][c][\"y\"]\n",
    "    client_dls[\"base_test\"][c] = DataLoader(TimeSeriesDataset(Xbt,ybt), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    for i in range(NUM_TASKS):\n",
    "        key = f\"task_{i+1}\"\n",
    "        Xt, yt = task_lagged[key][c][\"X\"], task_lagged[key][c][\"y\"]\n",
    "        print(f\"ğŸ“ {c} - {key}: total = {len(Xt)}\")\n",
    "        \n",
    "        split = int(len(Xt)*SPLIT_RATIO)\n",
    "        client_dls[f\"{key}_train\"][c] = DataLoader(TimeSeriesDataset(Xt[:split], yt[:split]), batch_size=BATCH_SIZE, shuffle=True)\n",
    "        client_dls[f\"{key}_test\"][c]  = DataLoader(TimeSeriesDataset(Xt[split:], yt[split:]), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701d8b6-c336-4e6a-aaaf-a1b5ce68656a",
   "metadata": {},
   "source": [
    " <h1>5. Model & Utilities (Base training or loading)</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2277497a-dfca-4ff2-b64d-49307663b6b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, num_layers: int = 1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc   = nn.Linear(hidden_dim, output_dim)\n",
    "    def forward(self, x):  # x: [B, T, D]\n",
    "        out,_ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "INPUT_DIM = base_lagged[next(iter(base_lagged))][\"X\"].shape[2]\n",
    "HIDDEN_DIM = 64\n",
    "OUTPUT_DIM = PRED_LEN\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity = capacity\n",
    "        self.buffer: List[Tuple[torch.Tensor,torch.Tensor]] = []\n",
    "    def add(self, x, y):\n",
    "        if self.capacity == 0: return\n",
    "        if len(self.buffer) >= self.capacity: self.buffer.pop(0)\n",
    "        self.buffer.append((x.detach().cpu(), y.detach().cpu()))\n",
    "    def sample(self, batch_size: int):\n",
    "        if not self.buffer: return (None,None)\n",
    "        idx = np.random.choice(len(self.buffer), min(batch_size, len(self.buffer)), replace=False)\n",
    "        X, y = zip(*[self.buffer[i] for i in idx])\n",
    "        return torch.stack(X), torch.stack(y)\n",
    "    def __len__(self): return len(self.buffer)\n",
    "\n",
    "def compute_ewc_fisher(model: nn.Module, loader: DataLoader, device=DEVICE, num_batches=10):\n",
    "    model.eval().to(device)\n",
    "    fis = {n: torch.zeros_like(p, device=device) for n,p in model.named_parameters()}\n",
    "    count = 0\n",
    "    for X,y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        model.zero_grad()\n",
    "        loss = nn.functional.mse_loss(model(X), y)\n",
    "        loss.backward()\n",
    "        for n,p in model.named_parameters():\n",
    "            if p.grad is not None:\n",
    "                fis[n] += (p.grad.detach()**2)\n",
    "        count += 1\n",
    "        if count >= num_batches: break\n",
    "    for n in fis: fis[n] /= max(count,1)\n",
    "    return fis\n",
    "\n",
    "def init_base_buffer(predictor: nn.Module, loader: DataLoader, capacity=BUFFER_CAPACITY, sample_fraction=0.05):\n",
    "    predictor.eval()\n",
    "    Xs, Ys = [], []\n",
    "    with torch.no_grad():\n",
    "        for X,y in loader:\n",
    "            Xs.append(X.cpu()); Ys.append(y.cpu())\n",
    "    Xall = torch.cat(Xs, 0); Yall = torch.cat(Ys, 0)\n",
    "    embed = Xall.view(Xall.size(0), -1).numpy()\n",
    "    n_sel = max(1, int(sample_fraction * len(Xall)))\n",
    "    if n_sel >= len(embed):\n",
    "        sel_idx = np.arange(len(embed))\n",
    "    else:\n",
    "        km = KMeans(n_clusters=n_sel, random_state=42).fit(embed)\n",
    "        sel_idx = []\n",
    "        for k in range(n_sel):\n",
    "            ids = np.where(km.labels_ == k)[0]\n",
    "            if ids.size == 0: continue\n",
    "            D = np.linalg.norm(embed[ids] - km.cluster_centers_[k], axis=1)\n",
    "            sel_idx.append(ids[np.argmin(D)])\n",
    "    buf = ReplayBuffer(capacity)\n",
    "    for i in sel_idx: buf.add(Xall[i], Yall[i])\n",
    "    return buf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f333bbe-36d0-4958-b0f5-a9385a7478d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f99ce83-bf82-4f5f-a902-f8866fddf183",
   "metadata": {
    "scrolled": true
   },
   "source": [
    " <h1>6. Base Model: Train (optional) or Load (default for speed) </h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c3248f-c09c-4aeb-900a-133ddd31a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_federated_base(client_dls, input_dim, output_dim, hidden_dim=HIDDEN_DIM,\n",
    "                         num_rounds=NUM_ROUNDS_BASE, local_epochs=LOCAL_EPOCHS_BASE, lr=LR_BASE, device=DEVICE):\n",
    "    global_model = LSTMPredictor(input_dim, hidden_dim, output_dim).to(device)\n",
    "    gW = global_model.state_dict()\n",
    "\n",
    "    client_models = {}\n",
    "    si_omegas, si_prev, si_W = {}, {}, {}\n",
    "\n",
    "    for r in range(num_rounds):\n",
    "        local_states = []\n",
    "        for c, loader in client_dls[\"base_train\"].items():\n",
    "            m = LSTMPredictor(input_dim, hidden_dim, output_dim).to(device)\n",
    "            m.load_state_dict(gW); m.train()\n",
    "            opt = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "            prev = {n: p.clone().detach() for n,p in m.named_parameters()}\n",
    "            W    = {n: torch.zeros_like(p) for n,p in m.named_parameters()}\n",
    "            for _ in range(local_epochs):\n",
    "                for X,y in loader:\n",
    "                    X,y = X.to(device), y.to(device)\n",
    "                    opt.zero_grad(); loss = nn.functional.mse_loss(m(X), y)\n",
    "                    loss.backward(); opt.step()\n",
    "                    for n,p in m.named_parameters():\n",
    "                        if p.grad is not None:\n",
    "                            delta = p.detach() - prev[n]\n",
    "                            W[n] += delta * (-p.grad.detach())\n",
    "            local_states.append({k: v.detach().clone() for k,v in m.state_dict().items()})\n",
    "            client_models[c] = m\n",
    "            # SI omega\n",
    "            omega = {}\n",
    "            for n,p in m.named_parameters():\n",
    "                delta = p.detach() - prev[n]\n",
    "                omega[n] = W[n] / (delta.pow(2) + 1e-3)\n",
    "            si_omegas[c] = omega; si_prev[c] = {n: p.clone().detach() for n,p in m.named_parameters()}\n",
    "            si_W[c] = W\n",
    "\n",
    "        # FedAvg\n",
    "        newW = {k: sum(ls[k] for ls in local_states)/len(local_states) for k in local_states[0].keys()}\n",
    "        gW = newW\n",
    "\n",
    "    global_model.load_state_dict(gW)\n",
    "    return global_model, client_models, si_omegas, si_prev, si_W\n",
    "\n",
    "base_model, base_clients, si_omegas, si_prev, si_W = train_federated_base(\n",
    "        client_dls, INPUT_DIM, OUTPUT_DIM, hidden_dim=HIDDEN_DIM, num_rounds=NUM_ROUNDS_BASE,\n",
    "        local_epochs=LOCAL_EPOCHS_BASE, lr=LR_BASE, device=DEVICE\n",
    "    )\n",
    "\n",
    "CLIENT_DATALOADERS = client_dls           # your dataloaders dict\n",
    "BASE_MODEL        = base_model            # global base model\n",
    "BASE_CLIENTS      = base_clients          # per-client base models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a0ca66-5575-4909-bfd6-e3fe52abad4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab36aef3-a830-44b1-a9b8-8df36f29867d",
   "metadata": {},
   "source": [
    " <h1>7. Initialize Replay Buffers & Fisher (once)  </h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed83aa8a-0007-47ba-9d14-3fae5b230e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_buffers = {}\n",
    "for c in client_dls[\"base_train\"]:\n",
    "    initial_buffers[c] = init_base_buffer(base_model, client_dls[\"base_train\"][c],\n",
    "                                          capacity=BUFFER_CAPACITY, sample_fraction=REPLAY_RATIO)\n",
    "\n",
    "fisher = {}\n",
    "for c in client_dls[\"base_train\"]:\n",
    "    ref = base_clients.get(c, base_model)  # fall back to global if no per-client base\n",
    "    fisher[c] = compute_ewc_fisher(ref, client_dls[\"base_train\"][c], device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f29669-b3ca-4f63-9d58-7529ba3fae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d2ec9-5942-45df-b5f4-b236136ba4af",
   "metadata": {},
   "source": [
    "  <h1>8. Continual Learning </h1>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3afd36a2-7832-4b87-b1ac-6aac50a384da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continual_learning_hybrid(\n",
    "    client_dataloaders,\n",
    "    client_buffers,\n",
    "    base_predictor,\n",
    "    base_clients,           # used by EWC classic refs\n",
    "    num_tasks,\n",
    "    num_rounds_dict,\n",
    "    local_epochs,\n",
    "    lr,\n",
    "    device,\n",
    "    mode,\n",
    "    replay_ratio,\n",
    "    distil_coef,\n",
    "    EwcCoeff,\n",
    "    online_ewc_coeff,\n",
    "    replay_coeff,\n",
    "    fisher_matrices=None,\n",
    "    si_coeff=None,               # SI Î»\n",
    "    si_omegas=None,              # per-client per-param Ï‰\n",
    "    si_contributions=None,       # per-client per-param W accumulator\n",
    "    si_prev_params=None          # per-client Î¸* (previous task snapshot)\n",
    "):\n",
    "    import torch, copy, numpy as np\n",
    "    import torch.nn as nn\n",
    "    from sklearn.cluster import KMeans\n",
    "    import torch._dynamo\n",
    "    torch._dynamo.disable()\n",
    "\n",
    "    # Reconstruct dims from base model\n",
    "    in_dim  = base_predictor.lstm.input_size\n",
    "    hid_dim = base_predictor.lstm.hidden_size\n",
    "    out_dim = base_predictor.fc.out_features\n",
    "\n",
    "    global_predictor = copy.deepcopy(base_predictor).to(device)\n",
    "    global_weights = global_predictor.state_dict()\n",
    "\n",
    "    clients = list(client_dataloaders[\"base_train\"].keys())\n",
    "    replay_buffers = {c: copy.deepcopy(client_buffers[c]) for c in clients}\n",
    "    predictors = {c: copy.deepcopy(global_predictor) for c in clients}\n",
    "    checkpoints = []\n",
    "\n",
    "    # Online EWC reference weights\n",
    "    ewc_reference_weights = {c: copy.deepcopy(base_predictor) for c in clients}\n",
    "\n",
    "    for task_id in range(1, num_tasks + 1):\n",
    "        print(f\"\\nğŸ” Task {task_id}   mode = {mode}\")\n",
    "        task_train_key = f\"task_{task_id}_train\"\n",
    "\n",
    "        # --- SI: initialize per-task accumulators exactly like your original code ---\n",
    "        if mode in [\"si\", \"kd+si\", \"si+replay\", \"si+ewc\"]:\n",
    "            assert si_contributions is not None and si_omegas is not None and si_prev_params is not None, \\\n",
    "                \"Provide SI structures for SI modes.\"\n",
    "            for c in clients:\n",
    "                si_contributions.setdefault(c, {})\n",
    "                # zero tensors with correct shapes\n",
    "                for name, p in global_predictor.named_parameters():\n",
    "                    si_contributions[c][name] = torch.zeros_like(p, device=device)\n",
    "\n",
    "        assert isinstance(num_rounds_dict, dict) and mode in num_rounds_dict\n",
    "        num_rounds = num_rounds_dict[mode]\n",
    "        print(f\"num_rounds = {num_rounds}\")\n",
    "\n",
    "        for r in range(num_rounds):\n",
    "            print(f\"ğŸŒ Communication Round {r+1}/{num_rounds}\")\n",
    "            local_weights = []\n",
    "\n",
    "            for c in clients:\n",
    "                predictor = copy.deepcopy(global_predictor).to(device)\n",
    "                old_predictor = copy.deepcopy(predictors[c]).to(device)\n",
    "                loader = client_dataloaders[task_train_key][c]\n",
    "                buffer = replay_buffers[c]\n",
    "\n",
    "                optimizer = torch.optim.Adam(predictor.parameters(), lr=lr)\n",
    "                predictor.train()\n",
    "\n",
    "                for _ in range(local_epochs):\n",
    "                    for X, y in loader:\n",
    "                        X, y = X.to(device), y.to(device)\n",
    "\n",
    "                        # ---- forward & base loss ----\n",
    "                        y_pred = predictor(X)\n",
    "                        reg_loss = nn.functional.mse_loss(y_pred, y)\n",
    "\n",
    "                        # ---- optional losses ----\n",
    "                        replay_loss = 0.0\n",
    "                        kd_loss = 0.0\n",
    "                        ewc_loss = 0.0\n",
    "                        ewc_loss_online = 0.0\n",
    "                        si_loss = 0.0\n",
    "\n",
    "                        if mode in [\"replay\", \"kd+replay\", \"ewc+replay\", \"si+replay\"]:\n",
    "                            rX, rY = buffer.sample(X.shape[0])\n",
    "                            if rX is not None:\n",
    "                                rX, rY = rX.to(device), rY.to(device)\n",
    "                                rY_pred = predictor(rX)\n",
    "                                replay_loss = nn.functional.mse_loss(rY_pred, rY)\n",
    "\n",
    "                        if mode in [\"kd\", \"kd+replay\", \"ewc+kd\", \"kd+si\"]:\n",
    "                            with torch.no_grad():\n",
    "                                teacher_output = old_predictor(X).detach()\n",
    "                            kd_loss = nn.functional.mse_loss(y_pred, teacher_output)\n",
    "\n",
    "                        if fisher_matrices is not None:\n",
    "                            for name, p in predictor.named_parameters():\n",
    "                                F = fisher_matrices.get(c, {}).get(name, None)\n",
    "                                if F is None: \n",
    "                                    continue\n",
    "                                if mode in [\"ewc\"]:\n",
    "                                    ref_sd = base_clients[c].state_dict() if c in base_clients else base_predictor.state_dict()\n",
    "                                    p0 = ref_sd[name].to(device)\n",
    "                                    ewc_loss += (F * (p - p0).pow(2)).sum()\n",
    "                                if mode in [\"online_ewc\", \"ewc+replay\", \"ewc+kd\", \"si+ewc\"]:\n",
    "                                    pref = ewc_reference_weights[c].state_dict()[name].to(device)\n",
    "                                    ewc_loss_online += (F * (p - pref).pow(2)).sum()\n",
    "\n",
    "                        if mode in [\"si\", \"kd+si\", \"si+replay\", \"si+ewc\"]:\n",
    "                            for name, p in predictor.named_parameters():\n",
    "                                if name in si_omegas[c]:\n",
    "                                    omega = si_omegas[c][name]\n",
    "                                    theta_star = si_prev_params[c][name]\n",
    "                                    si_loss += (omega * (p - theta_star).pow(2)).sum()\n",
    "\n",
    "                        # ---- backprop ----\n",
    "                        loss = (reg_loss\n",
    "                                + replay_coeff * replay_loss\n",
    "                                + distil_coef * kd_loss\n",
    "                                + EwcCoeff * ewc_loss\n",
    "                                + online_ewc_coeff * ewc_loss_online\n",
    "                                + (si_coeff or 0.0) * si_loss)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "\n",
    "                        # ====== SI contribution update (CORRECT) ======\n",
    "                        # snapshot Î¸(t) BEFORE the optimizer step\n",
    "                        pre_step = {n: p.detach().clone() for n, p in predictor.named_parameters()}\n",
    "                        optimizer.step()\n",
    "                        # now Î¸(t+1) is in-place; accumulate W += Î”Î¸ * (âˆ’g)\n",
    "                        if mode in [\"si\", \"kd+si\", \"si+replay\", \"si+ewc\"]:\n",
    "                            for name, p in predictor.named_parameters():\n",
    "                                g = p.grad  # grad from current loss (still present)\n",
    "                                if g is not None:\n",
    "                                    delta = p.detach() - pre_step[name]\n",
    "                                    si_contributions[c][name] += delta * (-g.detach())\n",
    "                        # ==============================================\n",
    "\n",
    "                local_weights.append(copy.deepcopy(predictor.state_dict()))\n",
    "\n",
    "            # FedAvg\n",
    "            newW = copy.deepcopy(local_weights[0])\n",
    "            for k in newW:\n",
    "                for i in range(1, len(local_weights)):\n",
    "                    newW[k] += local_weights[i][k]\n",
    "                newW[k] /= len(local_weights)\n",
    "\n",
    "            global_predictor.load_state_dict(newW)\n",
    "            for c in clients:\n",
    "                predictors[c] = copy.deepcopy(global_predictor)\n",
    "\n",
    "        # ---- Immutable checkpoint after finishing this task ----\n",
    "        snap = LSTMPredictor(in_dim, hid_dim, out_dim).to(device)\n",
    "        snap.load_state_dict({k: v.detach().clone() for k, v in global_predictor.state_dict().items()}, strict=True)\n",
    "        for p in snap.parameters(): p.requires_grad_(False)\n",
    "        checkpoints.append(snap)\n",
    "\n",
    "        # ---- Online EWC updates ----\n",
    "        if mode in [\"online_ewc\", \"ewc+replay\", \"ewc+kd\", \"si+ewc\"] and fisher_matrices is not None:\n",
    "            for c in clients:\n",
    "                new_loader = client_dataloaders[task_train_key][c]\n",
    "                new_fisher = compute_ewc_fisher(predictors[c], new_loader, device=device)\n",
    "                for name, val in new_fisher.items():\n",
    "                    old_val = fisher_matrices[c].get(name, 0.0)\n",
    "                    fisher_matrices[c][name] = 0.9 * old_val + 0.1 * val\n",
    "                ewc_reference_weights[c] = copy.deepcopy(predictors[c])\n",
    "\n",
    "        # ---- SI omega update & Î¸* snapshot (EXACT) ----\n",
    "        if mode in [\"si\", \"kd+si\", \"si+replay\", \"si+ewc\"]:\n",
    "            xi = 1e-3\n",
    "            for c in clients:\n",
    "                final_params = predictors[c]\n",
    "                for name, p in final_params.named_parameters():\n",
    "                    delta_total = p.detach() - si_prev_params[c][name]  # Î¸(T) - Î¸*\n",
    "                    W = si_contributions[c][name]\n",
    "                    si_omegas[c][name] += W / (delta_total.pow(2) + xi)\n",
    "                    si_prev_params[c][name] = p.detach().clone()\n",
    "                # reset accumulators\n",
    "                for name in si_contributions[c]:\n",
    "                    si_contributions[c][name].zero_()\n",
    "\n",
    "        # ---- K-means replay update ----\n",
    "        for c in clients:\n",
    "            if getattr(replay_buffers[c], \"capacity\", 0) <= 0:\n",
    "                continue\n",
    "            loader = client_dataloaders[task_train_key][c]\n",
    "            all_X, all_y = [], []\n",
    "            global_predictor.eval()\n",
    "            with torch.no_grad():\n",
    "                for X, y in loader:\n",
    "                    all_X.append(X.cpu()); all_y.append(y.cpu())\n",
    "            if not all_X:\n",
    "                continue\n",
    "            all_X = torch.cat(all_X, 0); all_y = torch.cat(all_y, 0)\n",
    "            X_embed = all_X.view(all_X.size(0), -1).numpy()\n",
    "            n_total = len(all_X); n_sel = int(replay_ratio * n_total)\n",
    "            if n_sel <= 0: \n",
    "                continue\n",
    "            if n_sel >= len(X_embed):\n",
    "                sel = np.arange(n_total)\n",
    "            else:\n",
    "                km = KMeans(n_clusters=n_sel, random_state=42).fit(X_embed)\n",
    "                centers, labels = km.cluster_centers_, km.labels_\n",
    "                sel = []\n",
    "                for k in range(n_sel):\n",
    "                    ids = np.where(labels == k)[0]\n",
    "                    if ids.size == 0: continue\n",
    "                    D = np.linalg.norm(X_embed[ids] - centers[k], axis=1)\n",
    "                    sel.append(ids[np.argmin(D)])\n",
    "            for i in sel:\n",
    "                x_i, y_i = all_X[i], all_y[i]\n",
    "                if x_i.ndim == 2:\n",
    "                    replay_buffers[c].add(x_i, y_i)\n",
    "                elif x_i.ndim == 3:\n",
    "                    for j in range(x_i.shape[0]):\n",
    "                        replay_buffers[c].add(x_i[j], y_i[j])\n",
    "\n",
    "    return checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa78907-619c-4806-9765-02c8b8907ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6afc3dff-ae25-402e-8b20-74a759a61105",
   "metadata": {},
   "source": [
    "<h1>9. Run Ablation  & Evaluate   </h1>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "987f853c-8cf8-457f-9e2b-a2e75f3b8c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Running Mode: si =======\n",
      "\n",
      "ğŸ” Task 1   mode = si\n",
      "num_rounds = 25\n",
      "ğŸŒ Communication Round 1/25\n",
      "ğŸŒ Communication Round 2/25\n",
      "ğŸŒ Communication Round 3/25\n",
      "ğŸŒ Communication Round 4/25\n",
      "ğŸŒ Communication Round 5/25\n",
      "ğŸŒ Communication Round 6/25\n",
      "ğŸŒ Communication Round 7/25\n",
      "ğŸŒ Communication Round 8/25\n",
      "ğŸŒ Communication Round 9/25\n",
      "ğŸŒ Communication Round 10/25\n",
      "ğŸŒ Communication Round 11/25\n",
      "ğŸŒ Communication Round 12/25\n",
      "ğŸŒ Communication Round 13/25\n",
      "ğŸŒ Communication Round 14/25\n",
      "ğŸŒ Communication Round 15/25\n",
      "ğŸŒ Communication Round 16/25\n",
      "ğŸŒ Communication Round 17/25\n",
      "ğŸŒ Communication Round 18/25\n",
      "ğŸŒ Communication Round 19/25\n",
      "ğŸŒ Communication Round 20/25\n",
      "ğŸŒ Communication Round 21/25\n",
      "ğŸŒ Communication Round 22/25\n",
      "ğŸŒ Communication Round 23/25\n",
      "ğŸŒ Communication Round 24/25\n",
      "ğŸŒ Communication Round 25/25\n",
      "\n",
      "ğŸ” Task 2   mode = si\n",
      "num_rounds = 25\n",
      "ğŸŒ Communication Round 1/25\n",
      "ğŸŒ Communication Round 2/25\n",
      "ğŸŒ Communication Round 3/25\n",
      "ğŸŒ Communication Round 4/25\n",
      "ğŸŒ Communication Round 5/25\n",
      "ğŸŒ Communication Round 6/25\n",
      "ğŸŒ Communication Round 7/25\n",
      "ğŸŒ Communication Round 8/25\n",
      "ğŸŒ Communication Round 9/25\n",
      "ğŸŒ Communication Round 10/25\n",
      "ğŸŒ Communication Round 11/25\n",
      "ğŸŒ Communication Round 12/25\n",
      "ğŸŒ Communication Round 13/25\n",
      "ğŸŒ Communication Round 14/25\n",
      "ğŸŒ Communication Round 15/25\n",
      "ğŸŒ Communication Round 16/25\n",
      "ğŸŒ Communication Round 17/25\n",
      "ğŸŒ Communication Round 18/25\n",
      "ğŸŒ Communication Round 19/25\n",
      "ğŸŒ Communication Round 20/25\n",
      "ğŸŒ Communication Round 21/25\n",
      "ğŸŒ Communication Round 22/25\n",
      "ğŸŒ Communication Round 23/25\n",
      "ğŸŒ Communication Round 24/25\n",
      "ğŸŒ Communication Round 25/25\n",
      "\n",
      "ğŸ” Task 3   mode = si\n",
      "num_rounds = 25\n",
      "ğŸŒ Communication Round 1/25\n",
      "ğŸŒ Communication Round 2/25\n",
      "ğŸŒ Communication Round 3/25\n",
      "ğŸŒ Communication Round 4/25\n",
      "ğŸŒ Communication Round 5/25\n",
      "ğŸŒ Communication Round 6/25\n",
      "ğŸŒ Communication Round 7/25\n",
      "ğŸŒ Communication Round 8/25\n",
      "ğŸŒ Communication Round 9/25\n",
      "ğŸŒ Communication Round 10/25\n",
      "ğŸŒ Communication Round 11/25\n",
      "ğŸŒ Communication Round 12/25\n",
      "ğŸŒ Communication Round 13/25\n",
      "ğŸŒ Communication Round 14/25\n",
      "ğŸŒ Communication Round 15/25\n",
      "ğŸŒ Communication Round 16/25\n",
      "ğŸŒ Communication Round 17/25\n",
      "ğŸŒ Communication Round 18/25\n",
      "ğŸŒ Communication Round 19/25\n",
      "ğŸŒ Communication Round 20/25\n",
      "ğŸŒ Communication Round 21/25\n",
      "ğŸŒ Communication Round 22/25\n",
      "ğŸŒ Communication Round 23/25\n",
      "ğŸŒ Communication Round 24/25\n",
      "ğŸŒ Communication Round 25/25\n",
      "\n",
      "ğŸ” Task 4   mode = si\n",
      "num_rounds = 25\n",
      "ğŸŒ Communication Round 1/25\n",
      "ğŸŒ Communication Round 2/25\n",
      "ğŸŒ Communication Round 3/25\n",
      "ğŸŒ Communication Round 4/25\n",
      "ğŸŒ Communication Round 5/25\n",
      "ğŸŒ Communication Round 6/25\n",
      "ğŸŒ Communication Round 7/25\n",
      "ğŸŒ Communication Round 8/25\n",
      "ğŸŒ Communication Round 9/25\n",
      "ğŸŒ Communication Round 10/25\n",
      "ğŸŒ Communication Round 11/25\n",
      "ğŸŒ Communication Round 12/25\n",
      "ğŸŒ Communication Round 13/25\n",
      "ğŸŒ Communication Round 14/25\n",
      "ğŸŒ Communication Round 15/25\n",
      "ğŸŒ Communication Round 16/25\n",
      "ğŸŒ Communication Round 17/25\n",
      "ğŸŒ Communication Round 18/25\n",
      "ğŸŒ Communication Round 19/25\n",
      "ğŸŒ Communication Round 20/25\n",
      "ğŸŒ Communication Round 21/25\n",
      "ğŸŒ Communication Round 22/25\n",
      "ğŸŒ Communication Round 23/25\n",
      "ğŸŒ Communication Round 24/25\n",
      "ğŸŒ Communication Round 25/25\n",
      "\n",
      "ğŸ” Task 5   mode = si\n",
      "num_rounds = 25\n",
      "ğŸŒ Communication Round 1/25\n",
      "ğŸŒ Communication Round 2/25\n",
      "ğŸŒ Communication Round 3/25\n",
      "ğŸŒ Communication Round 4/25\n",
      "ğŸŒ Communication Round 5/25\n",
      "ğŸŒ Communication Round 6/25\n",
      "ğŸŒ Communication Round 7/25\n",
      "ğŸŒ Communication Round 8/25\n",
      "ğŸŒ Communication Round 9/25\n",
      "ğŸŒ Communication Round 10/25\n",
      "ğŸŒ Communication Round 11/25\n",
      "ğŸŒ Communication Round 12/25\n",
      "ğŸŒ Communication Round 13/25\n",
      "ğŸŒ Communication Round 14/25\n",
      "ğŸŒ Communication Round 15/25\n",
      "ğŸŒ Communication Round 16/25\n",
      "ğŸŒ Communication Round 17/25\n",
      "ğŸŒ Communication Round 18/25\n",
      "ğŸŒ Communication Round 19/25\n",
      "ğŸŒ Communication Round 20/25\n",
      "ğŸŒ Communication Round 21/25\n",
      "ğŸŒ Communication Round 22/25\n",
      "ğŸŒ Communication Round 23/25\n",
      "ğŸŒ Communication Round 24/25\n",
      "ğŸŒ Communication Round 25/25\n",
      "\n",
      "ğŸ” Task 6   mode = si\n",
      "num_rounds = 25\n",
      "ğŸŒ Communication Round 1/25\n",
      "ğŸŒ Communication Round 2/25\n",
      "ğŸŒ Communication Round 3/25\n",
      "ğŸŒ Communication Round 4/25\n",
      "ğŸŒ Communication Round 5/25\n",
      "ğŸŒ Communication Round 6/25\n",
      "ğŸŒ Communication Round 7/25\n",
      "ğŸŒ Communication Round 8/25\n",
      "ğŸŒ Communication Round 9/25\n",
      "ğŸŒ Communication Round 10/25\n",
      "ğŸŒ Communication Round 11/25\n",
      "ğŸŒ Communication Round 12/25\n",
      "ğŸŒ Communication Round 13/25\n",
      "ğŸŒ Communication Round 14/25\n",
      "ğŸŒ Communication Round 15/25\n",
      "ğŸŒ Communication Round 16/25\n",
      "ğŸŒ Communication Round 17/25\n",
      "ğŸŒ Communication Round 18/25\n",
      "ğŸŒ Communication Round 19/25\n",
      "ğŸŒ Communication Round 20/25\n",
      "ğŸŒ Communication Round 21/25\n",
      "ğŸŒ Communication Round 22/25\n",
      "ğŸŒ Communication Round 23/25\n",
      "ğŸŒ Communication Round 24/25\n",
      "ğŸŒ Communication Round 25/25\n",
      "\n",
      "ğŸ” Task 7   mode = si\n",
      "num_rounds = 25\n",
      "ğŸŒ Communication Round 1/25\n",
      "ğŸŒ Communication Round 2/25\n",
      "ğŸŒ Communication Round 3/25\n",
      "ğŸŒ Communication Round 4/25\n",
      "ğŸŒ Communication Round 5/25\n",
      "ğŸŒ Communication Round 6/25\n",
      "ğŸŒ Communication Round 7/25\n",
      "ğŸŒ Communication Round 8/25\n",
      "ğŸŒ Communication Round 9/25\n",
      "ğŸŒ Communication Round 10/25\n",
      "ğŸŒ Communication Round 11/25\n",
      "ğŸŒ Communication Round 12/25\n",
      "ğŸŒ Communication Round 13/25\n",
      "ğŸŒ Communication Round 14/25\n",
      "ğŸŒ Communication Round 15/25\n",
      "ğŸŒ Communication Round 16/25\n",
      "ğŸŒ Communication Round 17/25\n",
      "ğŸŒ Communication Round 18/25\n",
      "ğŸŒ Communication Round 19/25\n",
      "ğŸŒ Communication Round 20/25\n",
      "ğŸŒ Communication Round 21/25\n",
      "ğŸŒ Communication Round 22/25\n",
      "ğŸŒ Communication Round 23/25\n",
      "ğŸŒ Communication Round 24/25\n",
      "ğŸŒ Communication Round 25/25\n",
      "\n",
      "ğŸ” Task 8   mode = si\n",
      "num_rounds = 25\n",
      "ğŸŒ Communication Round 1/25\n",
      "ğŸŒ Communication Round 2/25\n",
      "ğŸŒ Communication Round 3/25\n",
      "ğŸŒ Communication Round 4/25\n",
      "ğŸŒ Communication Round 5/25\n",
      "ğŸŒ Communication Round 6/25\n",
      "ğŸŒ Communication Round 7/25\n",
      "ğŸŒ Communication Round 8/25\n",
      "ğŸŒ Communication Round 9/25\n",
      "ğŸŒ Communication Round 10/25\n",
      "ğŸŒ Communication Round 11/25\n",
      "ğŸŒ Communication Round 12/25\n",
      "ğŸŒ Communication Round 13/25\n",
      "ğŸŒ Communication Round 14/25\n",
      "ğŸŒ Communication Round 15/25\n",
      "ğŸŒ Communication Round 16/25\n",
      "ğŸŒ Communication Round 17/25\n",
      "ğŸŒ Communication Round 18/25\n",
      "ğŸŒ Communication Round 19/25\n",
      "ğŸŒ Communication Round 20/25\n",
      "ğŸŒ Communication Round 21/25\n",
      "ğŸŒ Communication Round 22/25\n",
      "ğŸŒ Communication Round 23/25\n",
      "ğŸŒ Communication Round 24/25\n",
      "ğŸŒ Communication Round 25/25\n",
      "\n",
      "ğŸ” Task 9   mode = si\n",
      "num_rounds = 25\n",
      "ğŸŒ Communication Round 1/25\n",
      "ğŸŒ Communication Round 2/25\n",
      "ğŸŒ Communication Round 3/25\n",
      "ğŸŒ Communication Round 4/25\n",
      "ğŸŒ Communication Round 5/25\n",
      "ğŸŒ Communication Round 6/25\n",
      "ğŸŒ Communication Round 7/25\n",
      "ğŸŒ Communication Round 8/25\n",
      "ğŸŒ Communication Round 9/25\n",
      "ğŸŒ Communication Round 10/25\n",
      "ğŸŒ Communication Round 11/25\n",
      "ğŸŒ Communication Round 12/25\n",
      "ğŸŒ Communication Round 13/25\n",
      "ğŸŒ Communication Round 14/25\n",
      "ğŸŒ Communication Round 15/25\n",
      "ğŸŒ Communication Round 16/25\n",
      "ğŸŒ Communication Round 17/25\n",
      "ğŸŒ Communication Round 18/25\n",
      "ğŸŒ Communication Round 19/25\n",
      "ğŸŒ Communication Round 20/25\n",
      "ğŸŒ Communication Round 21/25\n",
      "ğŸŒ Communication Round 22/25\n",
      "ğŸŒ Communication Round 23/25\n",
      "ğŸŒ Communication Round 24/25\n",
      "ğŸŒ Communication Round 25/25\n",
      "\n",
      "ğŸ” Task 10   mode = si\n",
      "num_rounds = 25\n",
      "ğŸŒ Communication Round 1/25\n",
      "ğŸŒ Communication Round 2/25\n",
      "ğŸŒ Communication Round 3/25\n",
      "ğŸŒ Communication Round 4/25\n",
      "ğŸŒ Communication Round 5/25\n",
      "ğŸŒ Communication Round 6/25\n",
      "ğŸŒ Communication Round 7/25\n",
      "ğŸŒ Communication Round 8/25\n",
      "ğŸŒ Communication Round 9/25\n",
      "ğŸŒ Communication Round 10/25\n",
      "ğŸŒ Communication Round 11/25\n",
      "ğŸŒ Communication Round 12/25\n",
      "ğŸŒ Communication Round 13/25\n",
      "ğŸŒ Communication Round 14/25\n",
      "ğŸŒ Communication Round 15/25\n",
      "ğŸŒ Communication Round 16/25\n",
      "ğŸŒ Communication Round 17/25\n",
      "ğŸŒ Communication Round 18/25\n",
      "ğŸŒ Communication Round 19/25\n",
      "ğŸŒ Communication Round 20/25\n",
      "ğŸŒ Communication Round 21/25\n",
      "ğŸŒ Communication Round 22/25\n",
      "ğŸŒ Communication Round 23/25\n",
      "ğŸŒ Communication Round 24/25\n",
      "ğŸŒ Communication Round 25/25\n",
      "\n",
      "ğŸ” Task 11   mode = si\n",
      "num_rounds = 25\n",
      "ğŸŒ Communication Round 1/25\n",
      "ğŸŒ Communication Round 2/25\n",
      "ğŸŒ Communication Round 3/25\n",
      "ğŸŒ Communication Round 4/25\n",
      "ğŸŒ Communication Round 5/25\n",
      "ğŸŒ Communication Round 6/25\n",
      "ğŸŒ Communication Round 7/25\n",
      "ğŸŒ Communication Round 8/25\n",
      "ğŸŒ Communication Round 9/25\n",
      "ğŸŒ Communication Round 10/25\n",
      "ğŸŒ Communication Round 11/25\n",
      "ğŸŒ Communication Round 12/25\n",
      "ğŸŒ Communication Round 13/25\n",
      "ğŸŒ Communication Round 14/25\n",
      "ğŸŒ Communication Round 15/25\n",
      "ğŸŒ Communication Round 16/25\n",
      "ğŸŒ Communication Round 17/25\n",
      "ğŸŒ Communication Round 18/25\n",
      "ğŸŒ Communication Round 19/25\n",
      "ğŸŒ Communication Round 20/25\n",
      "ğŸŒ Communication Round 21/25\n",
      "ğŸŒ Communication Round 22/25\n",
      "ğŸŒ Communication Round 23/25\n",
      "ğŸŒ Communication Round 24/25\n",
      "ğŸŒ Communication Round 25/25\n",
      "ğŸ”¢ [si] AvgPerf=0.133831 | AF=-0.000093 | AP=0.137443\n",
      "\n",
      "ğŸ“Š Final Results Table:\n",
      "    AvgForgetting  AvgPlasticity  AvgPerformance  CPUTime(s)\n",
      "si      -0.093192       0.137443        0.133831  515.840466\n"
     ]
    }
   ],
   "source": [
    "def run_combined_ablation(\n",
    "    MODES,\n",
    "    REPLAY_RATIO,\n",
    "    KD_COEFF,\n",
    "    EWC_COEFF,\n",
    "    ONLINE_EWC_COEFF,\n",
    "    REPLAY_COEFF,\n",
    "    FISHER_MATRICES,\n",
    "    SI_OMEGAS,\n",
    "    SI_CONTRIBUTIONS,\n",
    "    SI_PREV_PARAMS,\n",
    "    SI_COEFF,\n",
    "    CLIENT_DATALOADERS,\n",
    "    BASE_MODEL,\n",
    "    BASE_CLIENTS,\n",
    "    NUM_TASKS,\n",
    "    NUM_ROUNDS_CL,\n",
    "    LOCAL_EPOCHS,\n",
    "    LR,\n",
    "    DEVICE\n",
    "):\n",
    "    import copy, time\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    checkpoints_per_mode = {}\n",
    "\n",
    "    cpu_times = {}\n",
    "\n",
    "    saved_base_weights = BASE_MODEL.state_dict()\n",
    "\n",
    "    for mode in MODES:\n",
    "        print(f\"\\n======= Running Mode: {mode} =======\")\n",
    "\n",
    "        # SI payloads per mode\n",
    "        if mode in [\"si\", \"kd+si\", \"si+replay\", \"si+ewc\"]:\n",
    "            si_omegas_mode = copy.deepcopy(SI_OMEGAS)\n",
    "            si_prev_params_mode = copy.deepcopy(SI_PREV_PARAMS)\n",
    "            si_contributions_mode = {}\n",
    "            for c in CLIENT_DATALOADERS[\"base_train\"]:\n",
    "                ref = BASE_CLIENTS.get(c, BASE_MODEL)   # <-- fallback ensures shapes exist\n",
    "                si_contributions_mode[c] = {name: torch.zeros_like(p) for name, p in ref.named_parameters()}\n",
    "        else:\n",
    "            si_omegas_mode = si_prev_params_mode = si_contributions_mode = None\n",
    "\n",
    "\n",
    "        # Replay buffers per mode (use your current name `initial_buffers`)\n",
    "        mode_replay_buffers = {}\n",
    "        for c in CLIENT_DATALOADERS[\"base_train\"]:\n",
    "            if mode in [\"replay\", \"ewc+replay\", \"kd+replay\", \"si+replay\"]:\n",
    "                original = initial_buffers[c]\n",
    "                buf = ReplayBuffer(capacity=original.capacity)\n",
    "                for x, y in original.buffer:\n",
    "                    if isinstance(x, torch.Tensor) and x.ndim == 2:\n",
    "                        buf.add(x, y)\n",
    "            else:\n",
    "                buf = ReplayBuffer(capacity=0)\n",
    "            mode_replay_buffers[c] = buf\n",
    "\n",
    "        # Reinit base for this mode\n",
    "        base_copy = LSTMPredictor(\n",
    "            input_dim=BASE_MODEL.lstm.input_size,\n",
    "            hidden_dim=BASE_MODEL.lstm.hidden_size,\n",
    "            output_dim=BASE_MODEL.fc.out_features\n",
    "        ).to(DEVICE)\n",
    "        base_copy.load_state_dict(saved_base_weights)\n",
    "\n",
    "        rounds_config = {\n",
    "            \"Naive\": NUM_ROUNDS_CL,\n",
    "            \"replay\": NUM_ROUNDS_CL,\n",
    "            \"kd\": NUM_ROUNDS_CL,\n",
    "            \"online_ewc\": NUM_ROUNDS_CL,\n",
    "            \"ewc\": NUM_ROUNDS_CL,\n",
    "            # keep combos for future use\n",
    "            \"si\": NUM_ROUNDS_CL, \"ewc+replay\": NUM_ROUNDS_CL, \"kd+si\": NUM_ROUNDS_CL,\n",
    "            \"si+ewc\": NUM_ROUNDS_CL, \"kd+replay\": NUM_ROUNDS_CL, \"ewc+kd\": NUM_ROUNDS_CL\n",
    "        }\n",
    "\n",
    "        kd_for_mode = KD_COEFF if mode in [\"kd\"] else 0.0\n",
    "\n",
    "        t0 = time.time()\n",
    "        checkpoints = continual_learning_hybrid(\n",
    "            client_dataloaders=CLIENT_DATALOADERS,\n",
    "            client_buffers=mode_replay_buffers,\n",
    "            base_predictor=base_copy,\n",
    "            base_clients=BASE_CLIENTS,\n",
    "            num_tasks=NUM_TASKS,\n",
    "            num_rounds_dict=rounds_config,\n",
    "            local_epochs=LOCAL_EPOCHS,\n",
    "            lr=LR,\n",
    "            device=DEVICE,\n",
    "            mode=mode,\n",
    "            replay_ratio=REPLAY_RATIO,\n",
    "            distil_coef=kd_for_mode,\n",
    "            EwcCoeff=EWC_COEFF,\n",
    "            online_ewc_coeff=ONLINE_EWC_COEFF,\n",
    "            replay_coeff=REPLAY_COEFF,\n",
    "            fisher_matrices=FISHER_MATRICES if mode in [\"ewc\", \"online_ewc\"] else None,\n",
    "            si_coeff=SI_COEFF,\n",
    "            si_omegas=si_omegas_mode,\n",
    "            si_contributions=si_contributions_mode,\n",
    "            si_prev_params=si_prev_params_mode\n",
    "        )\n",
    "        cpu_times[mode] = time.time() - t0\n",
    "        checkpoints_per_mode[mode] = checkpoints\n",
    "\n",
    "\n",
    "\n",
    "    return checkpoints_per_mode, cpu_times\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_rmse_matrix_and_metrics(ablation_checkpoints, client_dataloaders, cpu_times, device=DEVICE):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "    final_metrics = {}\n",
    "\n",
    "    for mode, checkpoints in ablation_checkpoints.items():\n",
    "        N = len(checkpoints)\n",
    "        # Legacy: zero-init matrices (unseen cells stay 0 instead of NaN)\n",
    "        rmse_matrix = np.zeros((N, N), dtype=float)\n",
    "        mae_matrix  = np.zeros((N, N), dtype=float)\n",
    "\n",
    "        # Fill lower triangle\n",
    "        for i, predictor in enumerate(checkpoints):\n",
    "            predictor.eval()\n",
    "            for j in range(i + 1):\n",
    "                task_key = f\"task_{j+1}_test\"\n",
    "                preds, trues = [], []\n",
    "                for _, loader in client_dataloaders[task_key].items():\n",
    "                    with torch.no_grad():\n",
    "                        for X, y in loader:\n",
    "                            X, y = X.to(device), y.to(device)\n",
    "                            preds.append(predictor(X).cpu().numpy().ravel())\n",
    "                            trues.append(y.cpu().numpy().ravel())\n",
    "                if preds and trues:\n",
    "                    P = np.concatenate(preds); Y = np.concatenate(trues)\n",
    "                    # Guard just in case\n",
    "                    if P.size and Y.size and np.isfinite(P).all() and np.isfinite(Y).all():\n",
    "                        rmse_matrix[i, j] = np.sqrt(mean_squared_error(Y, P))\n",
    "                        mae_matrix[i, j]  = mean_absolute_error(Y, P)\n",
    "                # else: leave zeros (legacy behavior)\n",
    "\n",
    "        # === Legacy metrics (match your original notebook) ===\n",
    "        # AvgPerf over tasks 1..N-1\n",
    "        last_row_rmse = rmse_matrix[-1, :-1] if N > 1 else rmse_matrix[-1:, -1:]\n",
    "        avg_perf = float(np.mean(last_row_rmse))\n",
    "\n",
    "        # AF over first N-1 tasks: P_{N,j} - P_{j,j}\n",
    "        diag_rmse = np.diag(rmse_matrix)\n",
    "        if N > 1:\n",
    "            af = float(np.mean(rmse_matrix[-1, :-1] - diag_rmse[:-1]))\n",
    "        else:\n",
    "            af = 0.0\n",
    "\n",
    "        # AP (legacy: diagonal mean; if you want strictly legacy, this matched your prints)\n",
    "        ap = float(np.mean(diag_rmse))\n",
    "\n",
    "        final_metrics[mode] = {\n",
    "            \"rmse_matrix\": rmse_matrix,\n",
    "            \"mae_matrix\": mae_matrix,\n",
    "            \"avg_perf\": avg_perf,\n",
    "            \"avg_forget_best\": float('nan'),     # unused in your table\n",
    "            \"avg_forget_taskwise\": af,\n",
    "            \"avg_plasticity\": ap,\n",
    "            \"last_model_rmse\": rmse_matrix[-1, :],\n",
    "            \"last_model_mae\":  mae_matrix[-1, :],\n",
    "            \"forgetting_vector_best\": np.array([]),\n",
    "            \"forgetting_vector_taskwise\": (rmse_matrix[-1, :-1] - diag_rmse[:-1]) if N > 1 else np.array([]),\n",
    "            \"cpu_time\": cpu_times[mode],\n",
    "        }\n",
    "\n",
    "        print(f\"ğŸ”¢ [{mode}] AvgPerf={avg_perf:.6f} | AF={af:.6f} | AP={ap:.6f}\")\n",
    "\n",
    "    return final_metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ===== Driver =====\n",
    "set_all_seeds(42)\n",
    "MODES = [\"Naive\",\"replay\", \"kd\", \"online_ewc\", \"ewc\", \"si\"]\n",
    "\n",
    "ablation_checkpoints, cpu_times = run_combined_ablation(\n",
    "    MODES=MODES,\n",
    "    REPLAY_RATIO=REPLAY_RATIO,\n",
    "    KD_COEFF=KD_COEFF,\n",
    "    EWC_COEFF=EWC_COEFF,\n",
    "    ONLINE_EWC_COEFF=ONLINE_EWC_COEFF,\n",
    "    REPLAY_COEFF=REPLAY_COEFF,\n",
    "    FISHER_MATRICES=fisher,\n",
    "    SI_OMEGAS=si_omegas,\n",
    "    SI_CONTRIBUTIONS=si_W,\n",
    "    SI_PREV_PARAMS=si_prev,\n",
    "    SI_COEFF=SI_COEFF,\n",
    "    CLIENT_DATALOADERS=CLIENT_DATALOADERS,\n",
    "    BASE_MODEL=BASE_MODEL,\n",
    "    BASE_CLIENTS=BASE_CLIENTS,\n",
    "    NUM_TASKS=NUM_TASKS,\n",
    "    NUM_ROUNDS_CL=NUM_ROUNDS_CL,\n",
    "    LOCAL_EPOCHS=LOCAL_EPOCHS,\n",
    "    LR=LR,\n",
    "    DEVICE=DEVICE\n",
    ")\n",
    "\n",
    "# Evaluate with your original logic\n",
    "final_metrics = evaluate_rmse_matrix_and_metrics(\n",
    "    ablation_checkpoints=ablation_checkpoints,\n",
    "    client_dataloaders=CLIENT_DATALOADERS,\n",
    "    cpu_times=cpu_times,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    mode: {\n",
    "        \"AvgForgetting\": metrics[\"avg_forget_taskwise\"] * 1000,  # your scaling\n",
    "        \"AvgPlasticity\": metrics[\"avg_plasticity\"],\n",
    "        \"AvgPerformance\": metrics[\"avg_perf\"],\n",
    "        \"CPUTime(s)\": metrics[\"cpu_time\"]\n",
    "    }\n",
    "    for mode, metrics in final_metrics.items()\n",
    "}).T\n",
    "\n",
    "print(\"\\nğŸ“Š Final Results Table:\")\n",
    "print(summary_df.round(7).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c109e-a0d1-4d58-bddf-b3fbf96b50d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a7d16-0b08-4b7a-a268-719f1917e167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc5bbe-eaab-4caa-a06a-91f4d2c6cb23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57c959-eef0-4212-93ae-3b255af1b7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f544c-f6fb-40ca-89f6-f16b2ad363ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a71df4-6337-41b9-8df2-a2899670d647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b780b-bf38-4502-8d23-9d2b19ea0975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d2475-7099-490e-94ee-77bb80b155d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aedae2-b85f-4c84-a442-75e0a7833ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eab3ec-8384-4967-980f-95cf7c84099f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25639139-1353-48b8-b789-817225e9e737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c4868-d00b-4c5b-8cc3-57054a552465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccdbcbf-1e83-468e-a035-6d1c1af1d59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d7242-f855-4a2f-b3eb-bb56ea42040c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65ac44fd-53bb-4e1b-b0f9-a31a1b830a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b947ec1e-925f-4905-87ed-f63ce7b04408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7557a7ba-8924-47a4-859a-2ff7464665fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "722374d7-2f0f-43ff-ae4a-547a4d74f0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a3fd9-2cb0-40a3-95fe-d709142142a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7da05-d6f3-47c0-b43e-04e7784dfa86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b4c74-db58-4041-b363-6f6464a89260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc8b4a-7bbc-4b2b-8488-4fff96cdede8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ffce5-ba3b-4ee9-9899-d384327b75df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c570804-daef-466c-8822-d62406c5b4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76768d-3251-47a1-9cf1-0347d7269cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41d3b9-6d87-4b67-b36f-cf603200e8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cdaeee-0865-493e-abaf-5f18b4b586fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2756d44-5956-480c-9c1a-328d9ff96299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd7339-730e-4514-b6a1-bf55abf838a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec0d2e-a331-479d-94f7-982f99ed2a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae8d2c-cb60-4ead-b8cd-3330d2134b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06772fb-6c3f-4e05-b079-b44d052ae76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a32caf-e5fb-4910-a9a0-f1f01717bc2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f701741-5671-4b42-b56d-1024bfe86231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d678e0f4-4386-4083-8cdf-ddcf3d76abe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d3334da-5861-411e-9cd8-5484cded1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8da514-fdfd-435b-ada1-c64820a6540a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257a854-ef75-49d1-8033-f87dc7fac7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4a199-7de2-4da1-9738-be22a115b216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582d0a0-5383-4048-91c5-ef3c99a3f623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56c3a4-f996-4a08-a262-03cca83e6fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a2d232-88d4-4256-b950-952d7f867ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c94c85-9403-491a-85b2-203317e0342c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89813e72-419a-40c4-a176-b3ab5031ae14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c2015-65ba-42bc-a42c-bd9920ab77ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdf5b2-3130-4501-95fa-5536265d8d25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5aaa8-af1f-4260-ad5d-8ff0e02e737c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a48ee2e-c1f7-4c34-afb7-8cd58b954a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b301a70-dd60-4586-89c0-48c9441370d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd59fc-fd94-4224-9b11-03a69e78d1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe47bd-4957-4f06-a8ba-5c388b0f75b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "01b48aa8-2c5d-477d-ad2a-67606dc86e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "dc6766f8-ba28-4b5b-84c2-28ab51ae6501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7119deda-89a7-412f-96b3-0967c618ebe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6ea98725-6b17-453e-92a2-9055e1d16d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbcdff1-195c-4152-a28b-f82e0278719e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8683c7-3e57-493c-a45e-8b58c7941818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "216a764c-09ae-42a0-b1fd-9045142ed603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6aa146-cce8-4b97-b61b-090cb003c441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28adf43f-8fc8-4bec-8f36-9dd081062484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ed8fa7da-2bf5-4f63-90f1-06925094e239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538f72d-6847-45fa-8391-d962b812b383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085442d9-936a-4b04-8c8e-da3ed228841c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "554d53ae-fb9c-4827-8073-1c0ec66603e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6a680-c815-49ea-8366-9665b516a155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e403cc5b-d24b-49c7-ad67-ed2389f6a13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e543c4f-2f63-4862-b51c-8df35a988dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7a55e-f5dc-44a6-93f1-589eda47dd4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b336cc-94b9-4fab-9f64-aa0db8f3a451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225785f-44d7-431c-82e6-031fe6744698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099a816-7857-452e-a95e-944515031275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd6134-5442-4a20-a039-3788a19d133c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933c00d-1c48-456f-9c18-c0e8f1139b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236db5a5-bfb6-479a-83b4-ec827f0a4b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5500f1-511d-4b7b-a458-65734195cfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ef0cf-6698-4455-9f94-827fb7cef5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832bd65-941c-4e1d-8cef-bae31b707d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d940aa5-a3fc-458f-988f-114a453d9063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d73c63-688c-4370-892b-65d829e46eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ee390-b3cb-403a-84a7-32782688b956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734cb135-295f-4c05-9c75-10ce4420b773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87e77b-5fb6-4f67-ac9b-c8436ecf3b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c8e9f-5570-48f5-bc17-503872987d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f4662-1886-410d-8d13-ee80eb1ae6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393fab5d-d65b-43b8-9f6e-355e9075ce5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477be51-b9b7-4bdf-b579-bf25de8c298f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ce495-4d8a-4f5d-b7bf-862dafb380ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e035b-81a2-4844-9ce9-19134777cb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968c3f8-dbd6-4ca5-8a80-abefaed85260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c597b55-5ea9-46a2-8219-0f034a4352f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f5bbaba-df28-4e78-a147-0a60b6bf3a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9daea-e824-419c-86c3-2dd69d820c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190eab5-2d0a-489c-878c-77bfecf9c5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
